{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading instruments SDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "import os \n",
    "import glob \n",
    "import math \n",
    "import pynmea2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data directory\n",
    "data_dir = 'C:/Users/ica/OneDrive - Plymouth Marine Laboratory/vscode/EC_co2_flux/EC flux processing/SDA_IMC/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get filenames in raw data files\n",
    "\n",
    "def file_name_dir(data_dir):\n",
    "    \"\"\"\n",
    "    get the raw EC data file names and directories\n",
    "\n",
    "    input:  the parent directory of the raw EC data\n",
    "    return: the EC data file names (_name) and directories(_dir)\n",
    "    \n",
    "    \"\"\"    \n",
    "\n",
    "    cr6_name = os.listdir(data_dir + '\\\\CR6')\n",
    "    GPS_name = os.listdir(data_dir + '\\\\Underway')\n",
    "    metek_name = os.listdir(data_dir + '\\\\Metek')\n",
    "    cr800_name = os.listdir(data_dir + '\\\\CR800')\n",
    "    Picarro_name = os.listdir(data_dir + '\\\\Picarro')\n",
    "\n",
    " \n",
    "    return cr6_name,GPS_name,metek_name,cr800_name,Picarro_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates lists of files to be processed \n",
    "cr6_name,GPS_name,metek_name,cr800_name,Picarro_name = file_name_dir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new folder to store the processed data\n",
    "new_folder_path = os.path.join(data_dir, \"L0_test\")\n",
    "\n",
    "# Create the new folder\n",
    "os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "# subfolders to create\n",
    "subfolders = [\"TimeAdjGases\", \"PML_WindsForMotcorr\", \"Ship_WindsForMotcorr\"]\n",
    "\n",
    "# subfolder inside \"L0\"\n",
    "for subfolder in subfolders:\n",
    "    os.makedirs(os.path.join(new_folder_path, subfolder), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to read raw data files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read underway\n",
    "def read_gps_file(filepath):\n",
    "    \"\"\"\n",
    "    Reads an NMEA file and extracts datetime, latitude, longitude, and speed.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'datetime': [],\n",
    "        'latitude': [],\n",
    "        'longitude': [],\n",
    "        'speed': []\n",
    "    }\n",
    "    \n",
    "    with open(filepath) as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Split timestamp from NMEA sentence\n",
    "                timestamp_str, nmea = line.strip().split(' $')\n",
    "                nmea = '$' + nmea\n",
    "                timestamp = pd.to_datetime(timestamp_str)\n",
    "                \n",
    "                if \"INVTG\" in nmea:\n",
    "                    msg = pynmea2.parse(nmea)\n",
    "                    if msg.spd_over_grnd_kts:\n",
    "                        speed = float(msg.spd_over_grnd_kts)\n",
    "                        data['datetime'].append(timestamp)\n",
    "                        data['speed'].append(speed)\n",
    "                        data['latitude'].append(None)\n",
    "                        data['longitude'].append(None)\n",
    "                        \n",
    "                elif \"INGGA\" in nmea:\n",
    "                    msg = pynmea2.parse(nmea)\n",
    "                    if msg.latitude and msg.longitude:\n",
    "                        lat = round(msg.latitude,6)\n",
    "                        lon = round(msg.longitude,6)\n",
    "                        if msg.lat_dir == 'S':\n",
    "                            lat = -lat\n",
    "                        if msg.lon_dir == 'W':\n",
    "                            lon = -lon\n",
    "                        data['datetime'].append(timestamp)\n",
    "                        data['latitude'].append(lat)\n",
    "                        data['longitude'].append(lon)\n",
    "                        data['speed'].append(None)\n",
    "                        \n",
    "            except (ValueError, pynmea2.ParseError) as e:\n",
    "                continue\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read underway.hdg.txt\n",
    "def read_hdg_file(filepath):\n",
    "    data = {\n",
    "        'datetime': [],\n",
    "        'heading': [],\n",
    "        'rate_of_turn': []\n",
    "    }\n",
    "    \n",
    "    with open(filepath) as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                timestamp_str, nmea = line.strip().split(' $')\n",
    "                nmea = '$' + nmea\n",
    "                timestamp = pd.to_datetime(timestamp_str)\n",
    "                \n",
    "                if \"INHDT\" in nmea:\n",
    "                    msg = pynmea2.parse(nmea)\n",
    "                    if msg.heading:\n",
    "                        heading = float(msg.heading)\n",
    "                        data['datetime'].append(timestamp)\n",
    "                        data['heading'].append(heading)\n",
    "                        data['rate_of_turn'].append(None)\n",
    "                      \n",
    "                elif \"INROT\" in nmea:\n",
    "                    msg = pynmea2.parse(nmea)\n",
    "                    if msg.rate_of_turn:\n",
    "                        rot = float(msg.rate_of_turn)\n",
    "                        data['datetime'].append(timestamp)\n",
    "                        data['heading'].append(None)\n",
    "                        data['rate_of_turn'].append(rot)\n",
    "                \n",
    "                        \n",
    "            except (ValueError, pynmea2.ParseError) as e:\n",
    "                continue\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmea_hdg_df = read_hdg_file('C:/Users/ica/OneDrive - Plymouth Marine Laboratory/vscode/EC_co2_flux/EC flux processing/SDA_IMC/data/Underway/2024-06-04T18-00-00Z-hdg.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmea_gps_df = read_gps_file('C:/Users/ica/OneDrive - Plymouth Marine Laboratory/vscode/EC_co2_flux/EC flux processing/SDA_IMC/data/Underway/2024-06-04T18-00-00Z-gps.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge GPS and heading data using datetime index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wind data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename  in cr6_name:\n",
    "    df= pd.read_csv(data_dir + '\\\\CR6\\\\' + filename, skiprows=1, delimiter = ',')\n",
    "    df = df.iloc[2:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cr6_file(df):\n",
    "    # Convert TIMESTAMP to datetime\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "    \n",
    "    # Get the first timestamp in the data\n",
    "    first_time = df['TIMESTAMP'].iloc[0]\n",
    "    \n",
    "    # Check if the timestamp starts at the top of the hour\n",
    "    if first_time.minute != 0 or first_time.second != 0:\n",
    "        # Calculate the next hour\n",
    "        next_hour = first_time.replace(minute=0, second=0) + pd.Timedelta(hours=1)\n",
    "        \n",
    "        # Filter data to keep only rows from the next hour\n",
    "        df = df[df['TIMESTAMP'] >= next_hour]\n",
    "        \n",
    "        # Create new filename with the next hour\n",
    "        new_filename = f\"CR6data_{next_hour.strftime('%Y_%m_%d_%H')}19.dat\"\n",
    "    else:\n",
    "        new_filename = None\n",
    "    \n",
    "    return df, new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def read_cr6_data(df):\n",
    "    # Convert TIMESTAMP to datetime and set as index\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "    df = df.set_index('TIMESTAMP')\n",
    "    \n",
    "    rad2deg = 180.0 / np.pi\n",
    "\n",
    "    # Convert columns to numeric, replacing empty strings with NaN\n",
    "    numeric_cols = ['SonicX', 'SonicY', 'SonicZ', 'SonicT',\n",
    "                   'ShipSonicX', 'ShipSonicY', 'ShipSonicZ', 'ShipSonicT',\n",
    "                   'RotX', 'RotY', 'RotZ', 'AccX', 'AccY', 'AccZ']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Calculate wind components\n",
    "    result_df = pd.DataFrame(index=df.index)\n",
    "    result_df['u_ms'] = df['SonicY'] / 100.0\n",
    "    result_df['v_ms'] = df['SonicX'] / -100.0\n",
    "    result_df['w_ms'] = df['SonicZ'] / 100.0\n",
    "    result_df['t_degC'] = df['SonicT'] / 100.0\n",
    "    \n",
    "    result_df['u_ms_ship'] = df['ShipSonicY'] / 100.0\n",
    "    result_df['v_ms_ship'] = df['ShipSonicX'] / -100.0\n",
    "    result_df['w_ms_ship'] = df['ShipSonicZ'] / 100.0\n",
    "    result_df['t_degC_ship'] = df['ShipSonicT'] / 100.0\n",
    "\n",
    "    # Rotation and Acceleration\n",
    "    result_df['rotx_degs'] = rad2deg * df['RotX'] / 1000.0\n",
    "    result_df['roty_degs'] = rad2deg * df['RotY'] / 1000.0\n",
    "    result_df['rotz_degs'] = rad2deg * df['RotZ'] / 1000.0\n",
    "    result_df['accelx_g'] = df['AccX'] / -1000.0\n",
    "    result_df['accely_g'] = df['AccY'] / -1000.0\n",
    "    result_df['accelz_g'] = df['AccZ'] / -1000.0\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluxes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
